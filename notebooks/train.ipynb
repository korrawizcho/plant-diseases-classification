{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\miniconda3\\envs\\plant_disease\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T # for simplifying the transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "from torchvision import models\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_ROOT = pathlib.Path(os.getcwd()).parent\n",
    "DATA_PATH = os.path.join(\n",
    "    PRJ_ROOT, 'data', 'rice_leaf_diseases'\n",
    ")\n",
    "\n",
    "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
    "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
    "\n",
    "TRAIN_BATCH = 1\n",
    "TEST_BATCH = 1\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes\n",
    "\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size, num_workers, train = False):\n",
    "    if train:\n",
    "        #train\n",
    "        transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n",
    "            T.RandomErasing(p=0.1, value='random')\n",
    "        ])\n",
    "        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform = transform)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        return train_loader, len(train_data)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # val/test\n",
    "        transform = T.Compose([ # We dont need augmentation for test transforms\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n",
    "        ])\n",
    "\n",
    "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n",
    "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        return val_loader, test_loader, len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_loader, train_data_len) = get_data_loaders(DATA_PATH, \n",
    "                                                  TRAIN_BATCH,\n",
    "                                                  NUM_WORKERS,\n",
    "                                                  train=True)\n",
    "(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(DATA_PATH,\n",
    "                                                                            TEST_BATCH,\n",
    "                                                                            NUM_WORKERS,\n",
    "                                                                            train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bacterial leaf blight', 'Brown spot', 'Leaf smut'] 3\n"
     ]
    }
   ],
   "source": [
    "classes = get_classes(os.path.join(DATA_PATH, \"train/\"))\n",
    "print(classes, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    \"train\": train_data_len,\n",
    "    \"val\": valid_data_len\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 24 24\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, for the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.device('cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(hub_url:str, model_name:str):\n",
    "    model = torch.hub.load(hub_url, model_name, pretrained=True)\n",
    "    for param in model.parameters(): #freeze model\n",
    "        param.requires_grad = False\n",
    "\n",
    "    n_inputs = model.head.in_features\n",
    "    model.head = nn.Sequential(\n",
    "        nn.Linear(n_inputs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, len(classes))\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "try:\n",
    "    from torchmetrics.functional import accuracy\n",
    "except ImportError:\n",
    "    from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "\n",
    "mlf_logger = MLFlowLogger(experiment_name=\"lightning_logs\", tracking_uri=\"file:./mlruns\")\n",
    "trainer = Trainer(logger=mlf_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS\n",
    "\n",
    "\n",
    "class PlantDiseasesModel(pl.LightningModule):\n",
    "    def __init__(self, hub_url:str, model_name:str, lr:float=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = init_model(hub_url, model_name)\n",
    "        self.criterion = LabelSmoothingCrossEntropy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # self.model.train()\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = MulticlassAccuracy(num_classes=len(classes), average=\"macro\")(preds, y)\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.model.head.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        steps_per_epoch = 45000 // TRAIN_BATCH\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                0.1,\n",
    "                epochs=self.trainer.max_epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\DELL/.cache\\torch\\hub\\SharanSMenon_swin-transformer-hub_main\n"
     ]
    }
   ],
   "source": [
    "model = PlantDiseasesModel(HUB_URL, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models/checkpoints\", exist_ok=True)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"../models/checkpoints\",\n",
    "    filename=\"best-checkpoint {epoch:02d}\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    auto_insert_metric_name=False)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    # accelerator=\"auto\",\n",
    "    logger=CSVLogger(save_dir=\"../logs/\"),\n",
    "    callbacks=[checkpoint_callback, LearningRateMonitor(logging_interval=\"step\"), TQDMProgressBar(refresh_rate=10)],\n",
    "    default_root_dir=\"../models/checkpoints/checkpoints.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/11 19:08:55 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "\n",
      "  | Name      | Type                       | Params\n",
      "---------------------------------------------------------\n",
      "0 | model     | SwinTransformer            | 27.9 M\n",
      "1 | criterion | LabelSmoothingCrossEntropy | 0     \n",
      "---------------------------------------------------------\n",
      "395 K     Trainable params\n",
      "27.5 M    Non-trainable params\n",
      "27.9 M    Total params\n",
      "111.658   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 96/96 [00:35<00:00,  2.68it/s, v_num=0, val_loss=0.898, val_acc=0.250]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 96/96 [00:36<00:00,  2.62it/s, v_num=0, val_loss=0.898, val_acc=0.250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/11 19:16:11 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpsivgbyy9\\model\\data, flavor: pytorch), fall back to return ['torch==2.0.0', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: dbe262513c6a424b8068003c86545b74\n",
      "artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'amsgrad': 'False', 'betas': '(0.9, 0.999)', 'capturable': 'False', 'differentiable': 'False', 'epochs': '10', 'eps': '1e-08', 'foreach': 'None', 'fused': 'None', 'lr': '0.01', 'maximize': 'False', 'optimizer_name': 'AdamW', 'weight_decay': '0.0005'}\n",
      "metrics: {'train_loss': 0.4141537547111511, 'val_acc': 0.2500000298023224, 'val_loss': 0.8976366519927979}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Train the model\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model,\n",
    "                train_dataloaders=dataloaders[\"train\"],\n",
    "                val_dataloaders=dataloaders[\"val\"])\n",
    "\n",
    "# fetch the auto logged parameters and metrics\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 24/24 [00:10<00:00,  2.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2500000298023224     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8976365923881531     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2500000298023224    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8976365923881531    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8976365923881531, 'test_acc': 0.2500000298023224}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 0a82b94c01bb4db091c071f88aecd3d0\n",
      "artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'amsgrad': 'False', 'betas': '(0.9, 0.999)', 'capturable': 'False', 'differentiable': 'False', 'epochs': '3', 'eps': '1e-08', 'foreach': 'None', 'fused': 'None', 'lr': '0.01', 'maximize': 'False', 'optimizer_name': 'AdamW', 'weight_decay': '0.0005'}\n",
      "metrics: {'test_acc': 0.2777778208255768, 'test_loss': 0.5474447011947632, 'train_loss': 0.3175453245639801, 'val_acc': 0.2777778208255768, 'val_loss': 0.5474446415901184}\n",
      "tags: {'Mode': 'testing'}\n"
     ]
    }
   ],
   "source": [
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_disease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
